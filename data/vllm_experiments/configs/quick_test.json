{
  "model_path": "THUDM/glm-4-9b-chat",
  "num_nodes": 8,
  "gpus_per_node": 8,
  "tensor_parallel_size": 1,
  "data_parallel_size": 64,
  "data_parallel_size_local": 8,
  "enable_expert_parallel": true,
  "distributed_executor_backend": "ray",
  "dtype": "bfloat16",
  "trust_remote_code": true,
  "max_seq_len_to_capture": 8192,
  "block_size": 16,
  "swap_space_gb": 20,
  "gpu_memory_utilization": 0.9,
  "max_num_batched_tokens": 8192,
  "max_num_seqs": 128,
  "max_model_len": 16384,
  "kv_cache_dtype": "auto",
  "enable_prefix_caching": false,
  "all2all_backend": "pplx",
  "enable_eplb": false,
  "enable_chunked_prefill": true,
  "max_num_partial_prefills": 1,
  "num_scheduler_steps": 2
}